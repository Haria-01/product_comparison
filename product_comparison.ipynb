{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b10b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a product name: Alisha Solid Women's Cycling Shorts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teja9\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:620: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "C:\\Users\\teja9\\AppData\\Local\\Temp/ipykernel_3400/847073850.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"Product name in Amazon\": most_similar_product,\n",
      "C:\\Users\\teja9\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:620: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "C:\\Users\\teja9\\AppData\\Local\\Temp/ipykernel_3400/847073850.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"Product name in Amazon\": 'N/A',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product name in Flipkart</th>\n",
       "      <th>Retail Price in Flipkart</th>\n",
       "      <th>Discounted Price in Flipkart</th>\n",
       "      <th>Product name in Amazon</th>\n",
       "      <th>Retail Price in Amazon</th>\n",
       "      <th>Discounted Price in Amazon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "      <td>999.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "      <td>982</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Product name in Flipkart Retail Price in Flipkart  \\\n",
       "0  Alisha Solid Women's Cycling Shorts                    999.0   \n",
       "\n",
       "  Discounted Price in Flipkart               Product name in Amazon  \\\n",
       "0                        379.0  Alisha Solid Women's Cycling Shorts   \n",
       "\n",
       "  Retail Price in Amazon Discounted Price in Amazon  \n",
       "0                    982                        438  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Read in the datasets\n",
    "dataset1 = pd.read_csv(\"amz_com-ecommerce_sample.csv\", encoding=\"unicode_escape\")\n",
    "dataset2 = pd.read_csv(\"flipkart_com-ecommerce_sample.csv\", encoding=\"unicode_escape\")\n",
    "\n",
    "# Get the product names from the datasets\n",
    "product_names1 = dataset1[\"product_name\"]\n",
    "product_names2 = dataset2[\"product_name\"]\n",
    "\n",
    "# Prompt the user for a product name\n",
    "product_name = input(\"Enter a product name: \")\n",
    "\n",
    "# Get the spaCy document for the user-specified product name\n",
    "product_doc = nlp(product_name)\n",
    "\n",
    "# Initialize a list to store the cosine similarities\n",
    "cosine_similarities = []\n",
    "\n",
    "# Iterate over the product names from the first dataset\n",
    "for name in product_names1:\n",
    "    # Get the spaCy document for the current product name\n",
    "    name_doc = nlp(name)\n",
    "    \n",
    "    # Convert the documents to numerical vectors\n",
    "    product_vec = product_doc.vector\n",
    "    name_vec = name_doc.vector\n",
    "    \n",
    "    # Compute the cosine similarity between the vectors\n",
    "    sim = 1 - cosine(product_vec, name_vec)\n",
    "    \n",
    "    # Store the cosine similarity in the list\n",
    "    cosine_similarities.append(sim)\n",
    "\n",
    "# Find the product name from the first dataset with the highest cosine similarity\n",
    "most_similar_index = cosine_similarities.index(max(cosine_similarities))\n",
    "most_similar_product = product_names1[most_similar_index]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\"Product name in Flipkart\", \"Retail Price in Flipkart\", \"Discounted Price in Flipkart\",\n",
    "                                \"Product name in Amazon\", \"Retail Price in Amazon\", \"Discounted Price in Amazon\"])\n",
    "\n",
    "# Add the most similar product from the first dataset to the DataFrame\n",
    "results = results.append({\"Product name in Amazon\": most_similar_product, \n",
    "                         \"Retail Price in Amazon\": dataset1[\"retail_price\"][most_similar_index],\n",
    "                         \"Discounted Price in Amazon\": dataset1[\"discounted_price\"][most_similar_index],\n",
    "                         \"Product name in Flipkart\": \"N/A\",\n",
    "                         \"Retail Price in Flipkart\": \"N/A\",\n",
    "                         \"Discounted Price in Flipkart\": \"N/A\"}, \n",
    "                        ignore_index=True)\n",
    "\n",
    "# Repeat the process for the product names from the second dataset\n",
    "# Initialize a list to store the cosine similarities\n",
    "cosine_similarities = []\n",
    "\n",
    "# Iterate over the product names from the first dataset\n",
    "for name in product_names2:\n",
    "    # Get the spaCy document for the current product name\n",
    "    name_doc = nlp(name)\n",
    "    \n",
    "    # Convert the documents to numerical vectors\n",
    "    product_vec = product_doc.vector\n",
    "    name_vec = name_doc.vector\n",
    "    \n",
    "    # Compute the cosine similarity between the vectors\n",
    "    sim = 1 - cosine(product_vec, name_vec)\n",
    "    \n",
    "    # Store the cosine similarity in the list\n",
    "    cosine_similarities.append(sim)\n",
    "\n",
    "# Find the product name from the first dataset with the highest cosine similarity\n",
    "most_similar_index = cosine_similarities.index(max(cosine_similarities))\n",
    "most_similar_product = product_names1[most_similar_index]\n",
    "\n",
    "# Add the most similar product from the first dataset to the DataFrame\n",
    "results = results.append({\"Product name in Amazon\": 'N/A', \n",
    "                         \"Retail Price in Amazon\": 'N/A',\n",
    "                         \"Discounted Price in Amazon\": 'N/A',\n",
    "                         \"Product name in Flipkart\": most_similar_product,\n",
    "                         \"Retail Price in Flipkart\": dataset2[\"retail_price\"][most_similar_index],\n",
    "                         \"Discounted Price in Flipkart\": dataset2[\"discounted_price\"][most_similar_index]}, \n",
    "                        ignore_index=True)\n",
    "\n",
    "for column in results.columns:\n",
    "    mode=results[column][1]\n",
    "    if results[column][0]=='N/A':\n",
    "      results[column][0]=results[column][1]\n",
    "\n",
    "results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97eaf08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a product name: Alisha Solid Women's Cycling Shorts\n",
      "Product name\tRetail price\tDiscount price\n",
      "Alisha Solid Women's Cycling Shorts \t 982 \t 438\n",
      "Alisha Solid Women's Cycling Shorts \t 379.0 \t 379.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the two data sets\n",
    "df1 = pd.read_csv('amz_com-ecommerce_sample.csv',encoding='unicode_escape')\n",
    "df2 = pd.read_csv('flipkart_com-ecommerce_sample.csv',encoding='unicode_escape')\n",
    "\n",
    "# Ask the user to input a product name\n",
    "product_name = input('Enter a product name: ')\n",
    "\n",
    "# Extract the product names, retail prices, and discount prices from the data sets\n",
    "products1 = df1['product_name'].tolist()\n",
    "products2 = df2['product_name'].tolist()\n",
    "prices1 = df1['retail_price'].tolist()\n",
    "prices2 = df2['discounted_price'].tolist()\n",
    "discounts1 = df1['discounted_price'].tolist()\n",
    "discounts2 = df2['discounted_price'].tolist()\n",
    "\n",
    "# Use the TfidfVectorizer to convert the product names into numerical vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors1 = vectorizer.fit_transform(products1)\n",
    "vectors2 = vectorizer.transform([product_name])\n",
    "\n",
    "# Find the index of the product in data set 1 with the highest cosine similarity to the user-specified product\n",
    "index1 = cosine_similarity(vectors1, vectors2).argmax()\n",
    "\n",
    "# Find the index of the product in data set 2 with the highest cosine similarity to the user-specified product\n",
    "index2 = cosine_similarity(vectors2, vectors1).argmax()\n",
    "\n",
    "# Print the results in a tabular column format\n",
    "print('Product name\\tRetail price\\tDiscount price')\n",
    "print(products1[index1], '\\t', prices1[index1], '\\t', discounts1[index1])\n",
    "print(products2[index2], '\\t', prices2[index2], '\\t', discounts2[index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acfb0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.20.8-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.20.8\n",
      "  Downloading Levenshtein-0.20.8-cp39-cp39-win_amd64.whl (100 kB)\n",
      "Collecting rapidfuzz<3.0.0,>=2.3.0\n",
      "  Downloading rapidfuzz-2.13.4-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.20.8 python-Levenshtein-0.20.8 rapidfuzz-2.13.4\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1282f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a product name: Alisha Solid Women's Cycling Shorts\n",
      "Product Name\tRetail Price\tDiscount Price\n",
      "Alisha Solid Women's Cycling Shorts\t982\t438\n",
      "Alisha Solid Women's Cycling Shorts\t999.0\t379.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load the two data sets\n",
    "df1 = pd.read_csv('amz_com-ecommerce_sample.csv',encoding='unicode_escape')\n",
    "df2 = pd.read_csv('flipkart_com-ecommerce_sample.csv',encoding='unicode_escape')\n",
    "\n",
    "# Extract the product names, retail prices, and discount prices from the data sets\n",
    "products1 = df1['product_name'].tolist()\n",
    "retail_prices1 = df1['retail_price'].tolist()\n",
    "discount_prices1 = df1['discounted_price'].tolist()\n",
    "products2 = df2['product_name'].tolist()\n",
    "retail_prices2 = df2['retail_price'].tolist()\n",
    "discount_prices2 = df2['discounted_price'].tolist()\n",
    "\n",
    "# Prompt the user for a product name\n",
    "product_name = input('Enter a product name: ')\n",
    "\n",
    "# Find the index of the product in data set 1 with the given name\n",
    "index1 = products1.index(product_name)\n",
    "\n",
    "# Use fuzzy string matching to find the most similar product name in data set 2\n",
    "similar_products = process.extract(product_name, products2, limit=1)\n",
    "similar_product_name = similar_products[0][0]\n",
    "\n",
    "# Find the index of the most similar product in data set 2\n",
    "index2 = products2.index(similar_product_name)\n",
    "\n",
    "# Print the product details in a tabular column format\n",
    "print('Product Name\\tRetail Price\\tDiscount Price')\n",
    "print(product_name + '\\t' + str(retail_prices1[index1]) + '\\t' + str(discount_prices1[index1]))\n",
    "print(similar_product_name + '\\t' + str(retail_prices2[index2]) + '\\t' + str(discount_prices2[index2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eaf033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-serving-client\n",
      "  Downloading bert_serving_client-1.10.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\teja9\\anaconda3\\lib\\site-packages (from bert-serving-client) (1.22.4)\n",
      "Requirement already satisfied: pyzmq>=17.1.0 in c:\\users\\teja9\\anaconda3\\lib\\site-packages (from bert-serving-client) (22.2.1)\n",
      "Installing collected packages: bert-serving-client\n",
      "Successfully installed bert-serving-client-1.10.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install bert-tensorflow\n",
    "#!pip install bert-serving-server\n",
    "!pip install bert-serving-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387b9f7",
   "metadata": {},
   "source": [
    "To reduce the time complexity of the  code is to use vectorization to compute the cosine similarities between the product name and all the product names from both datasets at once. This will avoid the need to iterate over the product names and compute the cosine similarity for each one individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3416d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a product name: sds\n"
     ]
    }
   ],
   "source": [
    "from bert_serving.client import BertClient\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the datasets\n",
    "dataset1 = pd.read_csv(\"amz_com-ecommerce_sample.csv\", encoding=\"unicode_escape\")\n",
    "dataset2 = pd.read_csv(\"flipkart_com-ecommerce_sample.csv\", encoding=\"unicode_escape\")\n",
    "\n",
    "# Get the product names from the datasets\n",
    "product_names1 = dataset1[\"product_name\"]\n",
    "product_names2 = dataset2[\"product_name\"]\n",
    "\n",
    "# Prompt the user for a product name\n",
    "product_name = input(\"Enter a product name: \")\n",
    "\n",
    "# Connect to the BERT server\n",
    "bc = BertClient()\n",
    "\n",
    "# Encode the product name and all the product names from the datasets using BERT\n",
    "product_vec = bc.encode([product_name])\n",
    "product_vecs1 = bc.encode(product_names1)\n",
    "product_vecs2 = bc.encode(product_names2)\n",
    "\n",
    "# Compute the cosine similarity between the encoded product name and all the encoded product names from the first dataset\n",
    "cosine_similarities1 = 1 - cosine(product_vec, product_vecs1)\n",
    "\n",
    "# Find the product name from the first dataset with the highest cosine similarity\n",
    "most_similar_index1 = cosine_similarities1.argmax()\n",
    "most_similar_product1 = product_names1[most_similar_index1]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\"Product Name\", \"Retail Price\", \"Discounted Price\"])\n",
    "\n",
    "# Add the most similar product from the first dataset to the DataFrame\n",
    "results = results.append({\"Product Name\": most_similar_product1, \n",
    "                         \"Retail Price\": dataset1[\"retail_price\"][most_similar_index1],\n",
    "                         \"Discounted Price\": dataset1[\"discounted_price\"][most_similar_index1]}, \n",
    "                        ignore_index=True)\n",
    "\n",
    "# Compute the cosine similarity between the encoded product name and all the encoded product names from the second dataset\n",
    "cosine_similarities2 = 1 - cosine(product_vec, product_vecs2)\n",
    "\n",
    "# Find the product name from the second dataset with the highest cosine similarity\n",
    "most_similar_index2 = cosine_similarities2.argmax()\n",
    "most_similar_product2 = product_names2[most_similar_index2]\n",
    "\n",
    "# Add the most similar product from the second dataset to the DataFrame\n",
    "results = results.append({\"Product Name\": most_similar_product2, \n",
    "                         \"Retail Price\": dataset2[\"retail_price\"][most_similar_index2],\n",
    "                         \"Discounted Price\": dataset2[\"discounted_price\"][most_similar_index2]}, \n",
    "                        ignore_index=True)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60793c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the datasets\n",
    "dataset1 = pd.read_csv(\"amz_com-ecommerce_sample.csv\", encoding=\"unicode_escape\")\n",
    "dataset2 = pd.read_csv(\"flipkart_com-ecommerce_sample.csv\", encoding=\"unicode_escape\")\n",
    "\n",
    "# Get the product names from the datasets\n",
    "product_names1 = dataset1[\"product_name\"]\n",
    "product_names2 = dataset2[\"product_name\"]\n",
    "\n",
    "# Train a word2vec model on the product names\n",
    "model = Word2Vec(product_names1, min_count=1)\n",
    "\n",
    "# Prompt the user for a product name\n",
    "product_name = input(\"Enter a product name: \")\n",
    "\n",
    "# Get the vector for the user-specified product name\n",
    "product_vec = model.wv[product_name]\n",
    "\n",
    "# Initialize a list to store the cosine similarities\n",
    "cosine_similarities = []\n",
    "\n",
    "# Iterate over the product names from the first dataset\n",
    "for name in product_names1:\n",
    "    # Get the vector for the current product name\n",
    "    name_vec = model.wv[name]\n",
    "\n",
    "    # Compute the cosine similarity between the vectors\n",
    "    sim = 1 - cosine(product_vec, name_vec)\n",
    "\n",
    "    # Store the cosine similarity in the list\n",
    "    cosine_similarities.append(sim)\n",
    "\n",
    "# Find the product name from the first dataset with the highest cosine similarity\n",
    "most_similar_index = cosine_similarities.index(max(cosine_similarities))\n",
    "most_similar_product = product_names1[most_similar_index]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\"Product name in Flipkart\", \"Retail Price in Flipkart\", \"Discounted Price in Flipkart\",\n",
    "                                \"Product name in Amazon\", \"Retail Price in Amazon\", \"Discounted Price in Amazon\"])\n",
    "\n",
    "# Add the most similar product from the first dataset to the DataFrame\n",
    "results = results.append({\"Product name in Amazon\": most_similar_product, \n",
    "                         \"Retail Price in Amazon\": dataset1[\"retail_price\"][most_similar_index],\n",
    "                         \"Discounted Price in Amazon\": dataset1[\"discounted_price\"][most_similar_index],\n",
    "                         \"Product name in Flipkart\": \"N/A\",\n",
    "                         \"Retail Price in Flipkart\": \"N/A\",\n",
    "                         \"Discounted Price in Flipkart\": \"N/A\"}, \n",
    "                        ignore_index=True)\n",
    "\n",
    "# Repeat the process for the product names from the second dataset\n",
    "# Initialize a list to store the cosine similarities\n",
    "cosine_similarities = []\n",
    "\n",
    "# Iterate over the product names from the first dataset\n",
    "for name in product_names2:\n",
    "    # Get the vector for the current product name\n",
    "    name_vec = model.wv[name]\n",
    "\n",
    "    # Compute the cosine similarity between the vectors\n",
    "    sim = 1 - cosine(product_vec, name_vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec51723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f37b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7f6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb8b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc182c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ee724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9bda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d4b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbe71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8990fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213afa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e368aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20620e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
